<section data-background-image="imgs/backgrounds/gray-01.png">
<h3>Algorithm</h3>
<pre><code data-line-numbers="1|2|3|4-5|6|7|8|9-12|16|18">Set K, it_max and area_min
Compute edges of the input image
Place initial seeds Sk depending on the edges density
Set label L_i = 0 for each pixel
Set energy E_i = E_0 for each pixel
while #iter <= it_max do
	for each seed S_k do
		for each pixel in a 2Sx2S region around S_k do
			Compute the energy E_ik of the pixel w.r.t. S_k
			if E_ik < E_i then
				E_i = E_ik
				L_i = k
			end if
		end for
	end for
	Update seeds values as S_k = mean(pixels with L_i == k)
end while
Merge small superpixels with bigger adjacent ones
</code></pre>
</section>

<section data-background-image="imgs/backgrounds/gray-01.png">
<h3>Seeds initialization</h3>
<font size="6">
<ul ul style="list-style-type:none;">
<li><p class="fragment">1. Regularly distribute the initial seeds in a grid with side $S = \sqrt{N/K}$</p></li>
<li><p class="fragment">2. Based on edge density inside each $S\times S$ region, add or delete seeds based on $T_{ad} = \dfrac{\sum{e_i}}{N}$:
\begin{equation}
\left\{
\begin{array}{lrcl}
\text{Add}, & \text{if } \dfrac{\left(\sum_S{e_i}\right)}{S^2} & > & 3\cdot T_{ad} \\
\text{Delete}, & \text{if } \dfrac{\left(\sum_S{e_i}\right)}{S^2} & < & T_{ad}\\
\end{array}
\right.
\end{equation}
</p></li>
<li><p class="fragment">3. Place seeds in the centroid of empty regions larger than $S\times S$</p></li>
</ul>
</font>
</section>

<section data-background-image="imgs/backgrounds/gray-01.png">
\begin{equation}
E_{lab} = \sqrt{(l_k - l_i)^2 + (a_k - a_i)^2 + (b_k - b_i)^2}
\end{equation}
\begin{equation}
E_{xy} = \sqrt{(x_k - x_i)^2 + (y_k - y_i)^2}
\end{equation}
</section>

<section data-background-image="imgs/backgrounds/gray-01.png">
<h3>Variation of Information (VOI)</h3>
Given two different clusterings $X=\{X_1, X_2, \ldots, X_k\}$ and $Y=\{Y_1, Y_2, \ldots, Y_l\}$<br>
$$VOI(X; Y) = -\sum_{i, j}r_{ij}\cdot\left[log\left(\frac{r_{ij}}{p_i}\right) + log\left(\frac{r_{ij}}{q_j}\right)\right]$$
$p_i = \frac{\mid X_i\mid}{N}$, $q_i = \frac{\mid Y_i\mid}{N}$, $r_{ij} = \frac{\mid X_i\mid \cap \mid Y_j\mid}{N} $
</section>

<section data-background-image="imgs/backgrounds/gray-01.png">
<h3>Undersegmentation Error</h3>
$$UE = \frac{1}{\mid GT\mid}\sum_{S\in GT}\left(\frac{\sum_{P:P\cap S\neq 0}min\left(\mid P_{in}\mid, \mid P_{out}\mid\right)}{\mid S\mid}\right)$$
</section>

<section data-background-image="imgs/backgrounds/gray-01.png">
<h3>Boundary Recall</h3>
$$BR = \frac{TP}{TP + FN}$$
</section>

<section data-background-image="imgs/backgrounds/gray-01.png">
<h3>Seeds initialization</h3>
<img data-src="chapters/superpixels/imgs/seeds/cartel2.png"; width=auto; height=200px>
<img data-src="chapters/superpixels/imgs/seeds/img1.png"; width=auto; height=200px>
<img data-src="chapters/superpixels/imgs/seeds/moon.png"; width=auto; height=200px>
<img data-src="chapters/superpixels/imgs/seeds/perrete.png"; width=auto; height=200px>
</section>

<section data-background-image="imgs/backgrounds/gray-01.png">
<h3>UE vs. VOI</h3>
<img data-src="chapters/superpixels/imgs/voi_vs_ue.png"; width=auto; height=300px>
<img data-src="chapters/superpixels/imgs/voi_vs_ue2.png"; width=auto; height=200px>
<aside class="notes">
Similar UE, lower VOI for BASS
</aside>
</section>

<section data-background-image="imgs/backgrounds/gray-01.png">
<img data-src="chapters/superpixels/imgs/results3.png">
</section>
<section data-background-image="imgs/backgrounds/gray-01.png">
<img data-src="chapters/superpixels/imgs/results4.png">
</section>

<section data-background-image="imgs/backgrounds/blue-01.png">
<h3>word2vec</h3>
Text preprocessing
<div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/embedding/imgs/fitter/fitter1-01.png">
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/embedding/imgs/fitter/fitter2-01.png">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/embedding/imgs/fitter/fitter3-01.png">
  <img class="fragment current-visible" data-fragment-index="2" src="chapters/embedding/imgs/fitter/fitter4-01.png">
  <img class="fragment current-visible" data-fragment-index="3" src="chapters/embedding/imgs/fitter/fitter5-01.png">
  <img class="fragment current-visible" data-fragment-index="4" src="chapters/embedding/imgs/fitter/fitter6-01.png">
</div>
</section>

<section data-background-image="imgs/backgrounds/blue-01.png">
<h3>word2vec</h3>
Example of a context window of 2 words
<img data-src="chapters/embedding/imgs/context.gif">
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Method</h2>
<img data-src="chapters/mainproduct/imgs/original.png"; width=auto; height=300px>
<img data-src="chapters/mainproduct/imgs/deformed.png"; width=auto; height=300px>
<img data-src="chapters/mainproduct/imgs/regular.png"; width=auto; height=300px>
</section>

<section data-background-image="imgs/backgrounds/blue-01.png">
<h3>word2vec</h3>
<img data-src="chapters/embedding/imgs/word_vectors.png">
</section>

<section data-background-image="imgs/backgrounds/blue-01.png">
<h3>Contrastive loss</h3>
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/embedding/imgs/contrastive/contrastive0.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/embedding/imgs/contrastive/contrastive1.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/embedding/imgs/contrastive/contrastive2.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="2" src="chapters/embedding/imgs/contrastive/contrastive3.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="3" src="chapters/embedding/imgs/contrastive/contrastive4.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="4" src="chapters/embedding/imgs/contrastive/contrastive5.png"; height="500">
</div>
</section>

<section data-background-image="imgs/backgrounds/blue-01.png">
<h3>Global loss</h3>
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/embedding/imgs/contrastive/losses1.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/embedding/imgs/contrastive/losses2.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/embedding/imgs/contrastive/losses3.png"; height="500">
</div>
</section>

<section data-background-image="imgs/backgrounds/blue-01.png">
<h3>Dataset categories</h3>
<small>
<table>
<tbody>
<tr>
<td>vest</td>
<td>hat</td>
<td>boots</td>
<td>polo</td>
</tr>
<tr>
<td>jewelry</td>
<td>skirt</td>
<td>clutch/wallet</td>
<td>cardigan</td>
</tr>
<tr>
<td>shirt</td>
<td>dress</td>
<td>backpack</td>
<td>swimwear</td>
</tr>
<tr>
<td>suits</td>
<td>travel bags</td>
<td>glasses/sunglasses</td>
<td>pants/leggings</td>
</tr>
<tr>
<td>flats</td>
<td>shorts</td>
<td>coat/cape</td>
<td>tops</td>
</tr>
<tr>
<td>pump/wedge</td>
<td>sweatshirt/hoodie</td>
<td>blazer</td>
<td>top handles</td>
</tr>
<tr>
<td>belts</td>
<td>jacket</td>
<td>other accessories</td>
<td>jumpsuits</td>
</tr>
<tr>
<td>sweater</td>
<td>joggers</td>
<td>sandals</td>
<td>crossbody/messenger bag</td>
</tr>
</tbody>
</table>
</small>
<aside class="notes">
32 categories
</aside>
</section>

<section data-background-image="imgs/backgrounds/blue-01.png">
<ul>
<li><b>1st approach: Bag of Words:</b> based on frequency, ignoring grammar or context. Also, vectors have 4k/8k dimensions depending on the training set.</li>
<li><b>2nd approach: word2vec:</b> shallow neural networks trained to reconstruct context. Vectors are distributed representations with a fixed dimension, independently on the training set.</li>
</ul>
</section>

<section data-background-image="imgs/backgrounds/blue-01.png">
<h2>Classification results</h2>
<table class="tg">
<thead>
  <tr>
    <th class="tg-18eh" rowspan="2">Model</th>
    <th class="tg-18eh" colspan="2">Classification accuracy</th>
  </tr>
  <tr>
    <td class="tg-18eh">Text</td>
    <td class="tg-18eh">Image</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0lax">Ours-baseline</td>
    <td class="tg-wp8o">99.78%</td>
    <td class="tg-wp8o">71.73%</td>
  </tr>
  <tr>
    <td class="tg-0lax">Ours-word2vec</td>
    <td class="tg-mqa1">99.97%</td>
    <td class="tg-mqa1">90.06%</td>
  </tr>
</tbody>
</table>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Quantitative results</h3>
<small>
<table class="tg">
<thead>
  <tr>
    <th class="tg-18eh" rowspan="2">Architecture</th>
    <th class="tg-18eh" colspan="2">Classification accuracy</th>
  </tr>
  <tr>
    <td class="tg-18eh">Text</td>
    <td class="tg-18eh">Image</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0lax">1. Full Image</td>
    <td class="tg-18eh">98.08%</td>
    <td class="tg-18eh">90.06%</td>
  </tr>
  <tr>
    <td class="tg-0lax">2. Bounding boxes</td>
    <td class="tg-wp8o">94.22%</td>
    <td class="tg-wp8o">88.63%</td>
  </tr>
  <tr>
    <td class="tg-0lax">3. 2 with overlap</td>
    <td class="tg-wp8o">97.24%</td>
    <td class="tg-wp8o">84.74%</td>
  </tr>
  <tr>
    <td class="tg-0lax">4. RoI pooling</td>
    <td class="tg-wp8o">96.91%</td>
    <td class="tg-wp8o">80.33%</td>
  </tr>
</tbody>
</table>
</small>
</section>


<section data-background-image="imgs/backgrounds/black-01.png">
<h3>Superpixel segmentation</h3>
<ul>
<li>Too many superpixels had to be annotated to select a meaningful region</li>
<li>Reducing the number of superpixels decreased the precision</li>
<li>The problem was solved with BASS</li>
<li>Evaluated in many different fashion and generic datasets with good results</li>
</ul>
</section>

<section data-background-image="imgs/backgrounds/black-01.png">
<h3>Superpixel segmentation: present and future work</h3>
<ul>
<li>Since 2015, superpixel segmentation has been tackled using deep learning techniques</li>
<li>One of the most relevant works is SSN (Superpixel Sampling Network), a differentiable end-to-end trainable superpixel segmentation algorithm</li>
<li>Our algorithm is well-suited to be treated with CNNs: inputs are images, and our energy functions can be used as losses</li>
</ul>
<aside class="notes">
Advantage: GPUs, try different optimizers, use data augmentation to regularize, get rid of hyperparameters
</aside>
</section>

<section data-background-image="imgs/backgrounds/black-01.png">
<h3>Multi-modal embedding</h3>
<ul>
<li>Creation of a multi-modal embedding capable of encapsulating images and texts</li>
<li>Good retrieval results with both images and texts as queries in a very challenging dataset</li>
<li>In addition, high precision values in classification</li>
</ul>
<aside class="notes">
The dataset is challenging due to big size and extremely similar products
</aside>
</section>

<section data-background-image="imgs/backgrounds/black-01.png">
<h3>Main product detection</h3>
<ul>
<li>Took advantage of the RoI pooling layer</li>
<li>New term added to the loss to maximize the overlap with the GT box</li>
</ul>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Network architecture</h3>
<style type="text/css">
#block1
{
    width: 50%;
    float: left;
}
#block2
{
    width: 50%;
    float: right;
}
#block3
{
    background-color: #F5F5F5;
    margin: 10px 20px;
    padding: 20px;
    width: 400px;
    float: right;
}
</style>
<div id="block1">
<ul>
<li>Common parts:
<ul>
<li>Contrastive loss</li>
<li>Classification loss</li>
<li>Global loss</li>
<li>Text network</li>
</ul>
</ul>
</div>
<div id="block2">
<ul>
<li>Different approaches:</li>
<ul style="list-style-type:none;">
<li>A. Full image</li>
<li>B. Bounding boxes</li>
<li>C. RoI pooling</li>
</ul>
</ul>
</div>
  </section>

<section data-background-image="imgs/backgrounds/red-01.png" >
<h3>Overlap loss</h3>
</div>
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/mainproduct/imgs/loss/loss1.png">
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/mainproduct/imgs/loss/loss2.png">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/mainproduct/imgs/loss/loss3.png">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/mainproduct/imgs/loss/loss4.png">
</div>
<aside class="notes">
Overlap loss is just L1 regression of GT and predicted overlap, computed as IoU
</aside>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Categories</h3>
<small>
<table>
<tbody>
<tr>
<td>vest</td>
<td>skirt</td>
</tr>
<tr>
<td>swimwear</td>
<td>suits</td>
</tr>
<tr>
<td>shorts</td>
<td>jumpsuits</td>
</tr>
<tr>
<td>shoes</td>
<td>pants</td>
</tr>
<tr>
<td>tops</td>
<td>hats</td>
</tr>
<tr>
<td>accessories</td>
<td>belts</td>
</tr>
<tr>
<td>glasses/sunglasses</td>
<td>backpack</td>
</tr>
<tr>
<td>bags</td>
<td>outerwear</td>
</tr>
<tr>
<td>dress</td>
<td>sweatshirt/sweaters</td>
</tr>
<tr>
<td>background</td>
</tr>
</tbody>
</table>
</small>
<aside class="notes">
19 categories
</aside>
</section>

<section data-background-image="imgs/backgrounds/red-01.png"
         >
<h3>Qualitative results</h3>
<div class="container">
  <img class="container__image" src="chapters/mainproduct/imgs/results/shirt.png"; height="400px">
  <div class="container__text">
  <small>
<ul style="list-style-type:none;">
<br>
<li> <b>Category:</b> Shirts & Blouses.</li>
<li><b>Description:</b> Men Color: Casual shirts. Le 31 - All-over check shirt. Regular fit Le 31. Exclusively from Le 31 for men.
 Trendy all-over checks redesigned in a palette perfect for the upcoming season. Regular fit Button-down collar. Contrasting underside. Ultra comfortable
 100% cotton poplin. The model is wearing size medium.</li>
<li><b>Title:</b> Le 31 - All-over check shirt Regular fit (Men, Red, XX- LARGE).</li>
<li><b>Color:</b> Khaki.</li>
</ul>
  </small>
  </div>
</div>
</section>

<section data-background-image="imgs/backgrounds/red-01.png"
         >
<h3>Qualitative results</h3>
<div class="container">
  <img class="container__image" src="chapters/mainproduct/imgs/results/tshirt2.png"; height="400px">
  <div class="container__text">
  <small>
<ul style="list-style-type:none;">
<br>
<li> <b>Category:</b> T-Shirts.</li>
<li><b>Description:</b> Women >T-Shirts. Twik - Solid high-neck tank Twik. Exclusively from Twik. A fitted
high-neck piece perfect for casual looks. Comfortable, stretch jersey. The model is wearing size small.</li>
<li><b>Title:</b> Twik - Solid high-neck tank (Women, Red, X- SMALL).</li>
<li><b>Color:</b> Ruby Red.</li>
</ul>
  </small>
  </div>
</div>
</section>

<section data-background-iframe="https://openai.com/blog/dall-e/"
          data-background-interactive>
</section>