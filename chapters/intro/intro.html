<section data-background-video="chapters/intro/videos/tesis-intro.mp4"
        data-background-video-loop data-background-video-muted>
</section>

<section data-background-image="imgs/backgrounds/colors-intro.png">
        <h3>Visual information</h3>
  <div class="r-stack">
  <p class="fragment fade-out" data-fragment-index="0" >Group of people outdoors</p>
  <p class="fragment current-visible" data-fragment-index="0" >Group of similar people in a similar place</p>
  <p class="fragment current-visible" data-fragment-index="1">Clothing analysis provides more information</p>
</div>
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/intro/imgs/staff.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/intro/imgs/futbol2.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/intro/imgs/futbol.png"; height="500">
</div>
</section>

<section data-background-image="imgs/backgrounds/colors-intro.png">
<h3>GOALS</h3>
<ul>
<li>Use <span class="fragment highlight-current-blue">Computer Vision</span> techniques to understand the relationship between the pixels of an image</li>
<li>Apply <span class="fragment highlight-current-blue">Artificial Intelligence</span> to extract and relate multi-modal information (images and texts)</li>
<li>Find the most <span class="fragment highlight-current-blue">relevant information</span> in an image based on textual information</li>
<ul>
</section>

<section data-background-image="imgs/backgrounds/colors-intro.png">
<a data-preview-link href="https://wideeyes.ai/">
<img data-src="chapters/intro/imgs/wideeyes.png"></a>
</section>

<section data-background-image="imgs/backgrounds/colors-intro.png">
<h3>Motivation</h3>
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/intro/imgs/ecommerce/ecommerce1.png">
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/intro/imgs/ecommerce/ecommerce2.png"; height="600">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/intro/imgs/ecommerce/ecommerce3.png"; height="600">
  <img class="fragment current-visible" data-fragment-index="2" src="chapters/intro/imgs/ecommerce/ecommerce4.png"; height="600">
</div>
</section>

<section data-background-image="imgs/backgrounds/colors-intro.png">
<h3>Motivation</h3>
Apparel e-commerce market size is increasing on a yearly basis.
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/embedding/imgs/ecommerce2.png"; height="400">
  <span class="fragment fade-in" data-fragment-index="0">Therefore, fashion is interesting from a <span class="fragment highlight-current-blue" data-fragment-index="1"><b>research point of view</b></span>
(challenging domain to extract visual information) and a <span class="fragment highlight-current-blue" data-fragment-index="2"><b>commercial point of view</b></span> (increasing market opportunities).
</div>
</section>

<section data-background-image="imgs/backgrounds/colors-intro.png">
        <h3>Quick overview</h3>
  <div class="r-stack">
  <p class="fragment current-visible" data-fragment-index="1" >Having well distributed superpixels for annotation</p>
  <p class="fragment current-visible" data-fragment-index="7" >Exploting multi-modal information for retrieval</p>
  <p class="fragment current-visible" data-fragment-index="11">Finding the relevant product in an e-commerce image</p>
</div>
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/intro/imgs/gif/intro1.png">
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/intro/imgs/gif/intro2.png">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/intro/imgs/gif/intro3.png">
  <img class="fragment current-visible" data-fragment-index="2" src="chapters/intro/imgs/gif/intro4.png">
  <img class="fragment current-visible" data-fragment-index="3" src="chapters/intro/imgs/gif/intro5.png">
  <img class="fragment current-visible" data-fragment-index="4" src="chapters/intro/imgs/gif/intro6.png">
  <img class="fragment current-visible" data-fragment-index="5" src="chapters/intro/imgs/gif/intro7.png">
  <img class="fragment current-visible" data-fragment-index="6" src="chapters/intro/imgs/gif/intro8.png">
  <img class="fragment current-visible" data-fragment-index="7" src="chapters/intro/imgs/gif/intro9.png">
  <img class="fragment current-visible" data-fragment-index="8" src="chapters/intro/imgs/gif/intro10.png">
  <img class="fragment current-visible" data-fragment-index="9" src="chapters/intro/imgs/gif/intro11.png">
  <img class="fragment current-visible" data-fragment-index="10" src="chapters/intro/imgs/gif/intro12.png">
  <img class="fragment current-visible" data-fragment-index="11" src="chapters/intro/imgs/gif/intro13.png">
  <img class="fragment current-visible" data-fragment-index="12" src="chapters/intro/imgs/gif/intro14.png">
  <img class="fragment current-visible" data-fragment-index="13" src="chapters/intro/imgs/gif/intro15.png">
</div>
</section>

<section data-background-image="imgs/backgrounds/colors-intro.png">
<h3>Contributions</h3>
<ol>
<font size="6">
<li><span class="fragment highlight-current-blue"><b>BASS Superpixel algorithm</b></span> new algorithm for image over-segmentation to generate more compact image representations.<br></li>
<li><span class="fragment highlight-current-blue"><b>Multi-modal embedding:</b></span> deep learning fashion-specific embedding for images and texts.<br></li>
<li><span class="fragment highlight-current-blue"><b>Product retrieval:</b></span> application of the embedding to find the closest image or text in a 1/2M products dataset.<br></li>
<li><span class="fragment highlight-current-blue"><b>Main product detection:</b></span> application of the embedding to a new task of finding the product being sold.<br></li>
</font>
</ol>
</section>

<section data-background-image="imgs/backgrounds/colors-intro.png">
<h3>Publications</h3>
<ul>
<font size="5">
<p><b>BASS: Boundary-Aware Superpixel Segmentation</b><br>
<em><span style="color:blue;">A. Rubio</span>, L. Yu, E. Simo-Serra, F. Moreno-Noguer</em><br>
ICPR 2016</p>
<p><b>Multi-modal Fashion Product Retrieval</b><br>
<em><span style="color:blue;">A. Rubio</span>, L. Yu, E. Simo-Serra, F. Moreno-Noguer</em><br>
WCL 2017</p>
<p><b>Multi-modal Joint Embedding for Fashion Product Retrieval</b><br>
<em><span style="color:blue;">A. Rubio</span>, L. Yu, E. Simo-Serra, F. Moreno-Noguer</em><br>
ICIP 2017</p>
<p><b>Multi-modal Embedding for Main Product Detection in Fashion</b><br>
<em><span style="color:blue;">A. Rubio</span>, L. Yu, E. Simo-Serra, F. Moreno-Noguer</em><br>
ICCV-CVF 2017<b><em><span class="fragment" style="color:green"><b style="word-space:2em">&nbsp;&nbsp;</b>(best paper award)</em></b></span></p>
</font>
</ul>
</section>

<section data-background-image="imgs/backgrounds/colors-intro.png">
  <img src="imgs/award.jpg"; height="600">
  </section>

<section data-background-image="imgs/backgrounds/colors-intro.png">
<h3>Publications</h3>
<ul>
<font size="5">
<p><b>BASS: Boundary-Aware Superpixel Segmentation</b><br>
<em><span style="color:blue;">A. Rubio</span>, L. Yu, E. Simo-Serra, F. Moreno-Noguer</em><br>
ICPR 2016</p>
<p><b>Multi-modal Fashion Product Retrieval</b><br>
<em><span style="color:blue;">A. Rubio</span>, L. Yu, E. Simo-Serra, F. Moreno-Noguer</em><br>
WCL 2017</p>
<p><b>Multi-modal Joint Embedding for Fashion Product Retrieval</b><br>
<em><span style="color:blue;">A. Rubio</span>, L. Yu, E. Simo-Serra, F. Moreno-Noguer</em><br>
ICIP 2017</p>
<p><b>Multi-modal Embedding for Main Product Detection in Fashion</b><br>
<em><span style="color:blue;">A. Rubio</span>, L. Yu, E. Simo-Serra, F. Moreno-Noguer</em><br>
ICCV-CVF 2017<b><em><span style="color:green"><b style="word-space:2em">&nbsp;&nbsp;</b>(best paper award)</em></b></span></p>
</font>
</ul>
</section>