<section id="mainproduct"
	 data-background-video="videos/chapter-red.mp4"
         data-background-video-loop data-background-video-muted>
	<h1><p class="fragment fade-in"; style="color:white;">MAIN PRODUCT DETECTION</p></h1>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<img data-src="chapters/mainproduct/imgs/teaser4.gif"; height=600px>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Goal</h2>
<p>Detect the <b><span class="fragment highlight-current-red">main product</span></b>, considering the case where the image
contains <span class="fragment highlight-current-red">several other garments</span> and has additional <span class="fragment highlight-current-red">metadata</span> associated.
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Motivation</h2>
Online products are normally presented tastefully <span class="fragment highlight-current-red">combined</span> and with <span class="fragment highlight-current-red">metadata</span>.<br>
</section>

<section data-background-iframe="https://www.oliveclothing.com/?_ga=2.110146957.961234722.1625700494-1019772797.1625700494"
          data-background-interactive>
</section>

<section data-background-iframe="https://bohemiantraders.com/?_ga=2.110146957.961234722.1625700494-1019772797.1625700494"
          data-background-interactive>
</section>

<!-- section data-background-iframe="https://cutterbuck.com/?_ga=2.110146957.961234722.1625700494-1019772797.1625700494"
          data-background-interactive>
</section-->

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Contributions</h2>
<ul>
<li>System to detect the most <span class="fragment highlight-current-red">relevant product</span> in a fashion image given the metadata.</li>
<li><span class="fragment highlight-current-red">Evaluation</span> of the method performance in a different e-commerce</li>
</ul>
<aside class="notes">
subsequently train specific product classifiers, which do not need to be fed with the whole image<br>
This allows to train specific product classifiers, or used as a first step in tasks like VQA.
</aside>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Related Work</h2>
<img data-src="chapters/mainproduct/imgs/MIE.png">
<ul>
<li>Text data consists of simple ImageNet labels</li>
<li>The authors retrieve labels closest to image regions</li>
</ul>
<aside class="notes">
automatic multi-labeling, try to generate object proposals
</aside>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Related Work</h2>
<ul>
<li>Focused on phrase localization</li>
<li>Only enforces ranking with hinge losses, not classification</li>
</ul>
<img data-src="chapters/mainproduct/imgs/moto.png">
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Related Work</h2>
<ul>
<li>Visual Question Answering (VQA)</li>
<li>Focused on many-to-many correspondences</li>
</ul>
<img data-src="chapters/mainproduct/imgs/cat.png">
<aside class="notes"
While they focus on many-to-many correspondences, i.e. relating parts of sentences to regions of images, our work tries to associate all the available textual metadata to only one region of the image.
</aside>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Method</h2>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Network inputs</h3>
</div>
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/mainproduct/imgs/inputs/network_inputs-01.png">
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/mainproduct/imgs/inputs/network_inputs-02.png">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/mainproduct/imgs/inputs/network_inputs-03.png">
</div>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Network architecture</h3>
<div class="r-stack">
  <p class="fragment current-visible" data-fragment-index="0" >Text branch, convolutional backbone and losses are common</p>
  <p class="fragment current-visible" data-fragment-index="1" >Input consisting of full images</p>
  <p class="fragment current-visible" data-fragment-index="2" >Input consisting of bounding boxes</p>
  <p class="fragment current-visible" data-fragment-index="3" >RoI pooling with images and box coords as input</p>
</div>
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/mainproduct/imgs/network/network1.png">
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/mainproduct/imgs/network/network2.png">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/mainproduct/imgs/network/network3.png">
  <img class="fragment current-visible" data-fragment-index="2" src="chapters/mainproduct/imgs/network/network4.png">
  <img class="fragment current-visible" data-fragment-index="3" src="chapters/mainproduct/imgs/network/network5.png">
</div>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Overlap loss</h3>
We also add an L1 regression <b>overlap loss</b> to predict the overlap between each bounding box and the ground truth
</div>
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/mainproduct/imgs/overlaps/overlaps-01.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/mainproduct/imgs/overlaps/overlaps-02.png"; height="500">
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/mainproduct/imgs/overlaps/overlaps-03.png"; height="500">
</div>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>RoI pooling</h3>
<div class="r-stretch">
<div class="r-stack">
  <p class="fragment fade-out" data-fragment-index="0">How to obtain the output descriptors for different boxes?</p>
  <p class="fragment current-visible" data-fragment-index="0" >A classical approach would do one forward pass per box</p>
  <p class="fragment current-visible" data-fragment-index="3" >Can we obtain multiple descriptors only with one forward pass?</p>
  <p class="fragment current-visible" data-fragment-index="4" >Using regions of interest (RoIs) it is possible</p>
  <p class="fragment current-visible" data-fragment-index="6" >RoI pooling produces same-size features for all RoIs</p>
</div>
  <div class="r-stack">
  <img class="fragment fade-out" data-fragment-index="0" src="chapters/mainproduct/imgs/roi/roi-01.png"; width=100%>
  <img class="fragment current-visible" data-fragment-index="0" src="chapters/mainproduct/imgs/roi/roi-02.png"; width=100%%>
  <img class="fragment current-visible" data-fragment-index="1" src="chapters/mainproduct/imgs/roi/roi-03.png"; width=100%%>
  <img class="fragment current-visible" data-fragment-index="2" src="chapters/mainproduct/imgs/roi/roi-04.png"; width=100%%>
  <img class="fragment current-visible" data-fragment-index="3" src="chapters/mainproduct/imgs/roi/roi-05.png"; width=100%%>
  <img class="fragment current-visible" data-fragment-index="4" src="chapters/mainproduct/imgs/roi/roi-06.png"; width=100%%>
  <img class="fragment current-visible" data-fragment-index="5" src="chapters/mainproduct/imgs/roi/roi-07.png"; width=100%%>
  <img class="fragment current-visible" data-fragment-index="6" src="chapters/mainproduct/imgs/roi/roi-08.png"; width=100%%>
  <img class="fragment current-visible" data-fragment-index="7" src="chapters/mainproduct/imgs/roi/roi-09.png"; width=100%%>
  <img class="fragment current-visible" data-fragment-index="8" src="chapters/mainproduct/imgs/roi/roi-10.png"; width=100%%>
<span class="fragment current-visible">
<ul>
<li>10x faster training / 20x faster testing</li>
<li>Input to our network in case C: 6x6x256 regions</li>
</ul>
</span>
</div>
</div>
<aside class="notes">
we can use the same feature map for all the proposals which enables us to pass the entire image to the CNN instead of passing all proposals individually.
</aside>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Dataset</h2>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Size and type of data</h3>
Images and metadata of products from fashion e-commerce sites.
<ul>
<li><b>Train:</b> 458,700 products from eight different e-commerces</li>
<li><b>Test:</b> 3,000 products from a different e-commerce with the GT bounding box</li>
</ul>
</section>

<section data-background-image="imgs/backgrounds/blue-01.png">
<h3>Dataset categories</h3>
<p><b>19 garment categories:</b> <em>accessories</em>, <em>pants</em>, <em>tops</em>, <em>bags</em>, ...</p>
<img data-src="chapters/mainproduct/imgs/categories/categories-04.png"; width=auto; height=310px>
<img data-src="chapters/mainproduct/imgs/categories/categories-05.png"; width=auto; height=310px>
<img data-src="chapters/mainproduct/imgs/categories/categories-06.png"; width=auto; height=310px>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Results</h2>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Methodology</h3>
<style type="text/css">
.container {
  border: 0px solid blue;
  padding: 0px 0px 0px;
  max-width: 100%;
  display: flex;
  &__image {
    margin: 0px 0px 0 0;
    width: 100%;
    object-fit: contain;
    align-self: flex-start;
  }
  &__text {
    flex: 1 1 auto;
  }
}
</style>
<div class="container">
  <!-- img class="container__image" src="https://mtdata.ru/u7/photo53A0/20946911428-0/original.jpg#20946911428"-->
  <video data-autoplay loop src="chapters/mainproduct/videos/mainprod-square.mp4"; height=400px></video>
  <div class="container__text">
<ul style="list-style-type:none;">
<li><p class="fragment">1. Extract features for the proposals</p></li>
<li><p class="fragment">2. Extract features for the text</p></li>
<li><p class="fragment">3. Compute distance</p></li>
<li><p class="fragment">4. Check overlap with the GT</p></li>
</ul>
  </div>
</div>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Qualitative results</h3>
<div class="container">
  <img class="container__image" src="chapters/mainproduct/imgs/results/tshirt.png"; height="400px">
  <div class="container__text">
  <small>
<ul style="list-style-type:none;">
<br>
<li> <b>Category:</b> T-Shirts.</li>
<li><b>Description:</b> Women >T- Shirts. Twik - Boyfriend tee Twik. Exclusively from Twik. An ultra practical must-have
neutral basic. Ultra comfortable 100% cotton weave. Sewn rolled sleeves. The model is wearing size small. </li>
<li><b>Title:</b> Twik - Boyfriend tee (Women, Green, X-SMALL).</li>
<li><b>Color:</b> Mossy Green.</li>
</ul>
  </small>
  </div>
</div>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Qualitative results</h3>
<div class="container">
  <img class="container__image" src="chapters/mainproduct/imgs/results/coat.png"; height="400px">
  <div class="container__text">
  <small>
<ul style="list-style-type:none;">
<br>
<li> <b>Category:</b> Coats & Jackets.</li>
<li><b>Description:</b> Women >Coats. Vero Moda - Long baseball jacket Vero Moda. Vero Moda at Icone A
preppy, chic and sporty piece for a trendy fall look. Blended wool with an ultra soft brushed finish and
fine satiny lining. Ribbed knit collar and cuffs Snap closure. Zip pockets. The model is wearing size small.</li>
<li><b>Title:</b> Vero Moda - Long baseball jacket (Women, Black, X-SMALL).</li>
<li><b>Color:</b> Black.</li>
</ul>
  </small>
  </div>
</div>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h3>Quantitative results</h3>
<small>
<table class="tg">
<thead>
  <tr>
    <th class="tg-18eh" rowspan="2">Architecture</th>
    <th class="tg-18eh" colspan="6">recall@top-K</th>
  </tr>
  <tr>
    <td class="tg-18eh">1</td>
    <td class="tg-18eh">3</td>
    <td class="tg-18eh">5</td>
    <td class="tg-18eh">20</td>
    <td class="tg-18eh">50</td>
    <td class="tg-18eh">100</td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0lax">1. Full Image</td>
    <td class="tg-baqh">21.87%</td>
    <td class="tg-baqh">44.74%</td>
    <td class="tg-baqh">58.48%</td>
    <td class="tg-baqh">76.06%</td>
    <td class="tg-baqh">79.58%</td>
    <td class="tg-baqh">82.47%</td>
  </tr>
  <tr>
    <td class="tg-0lax">2. B. boxes</td>
    <td class="tg-baqh"><span style="font-weight:400;font-style:normal">53.52% </span></td>
    <td class="tg-baqh">70.42%</td>
    <td class="tg-baqh">77.46%</td>
    <td class="tg-baqh">90.07%</td>
    <td class="tg-baqh">92.11%</td>
    <td class="tg-baqh">92.96%</td>
  </tr>
  <tr>
    <td class="tg-0lax">3. Overlap</td>
    <td class="tg-baqh"><span style="font-weight:400;font-style:normal">52.11%</span></td>
    <td class="tg-baqh">78.87%</td>
    <td class="tg-baqh">81.69%</td>
    <td class="tg-18eh">90.24%</td>
    <td class="tg-baqh">91.30%</td>
    <td class="tg-baqh">91.58%</td>
  </tr>
  <tr>
    <td class="tg-0lax">4. RoI pool.</td>
    <td class="tg-18eh">56.34%</td>
    <td class="tg-18eh">80.01%</td>
    <td class="tg-18eh">84.51%</td>
    <td class="tg-baqh">90.14%</td>
    <td class="tg-18eh">92.96%</td>
    <td class="tg-18eh">95.77%</td>
  </tr>
</tbody>
</table>
</small>
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<img data-src="chapters/mainproduct/imgs/tsne.png">
</section>

<section data-background-image="imgs/backgrounds/red-01.png">
<h2>Summary</h2>
<ul>
<li>Method that uses textual metadata to detect the product of interest in fashion e-commerce images.</li>
<li>Compact representations of bboxes from frozen layers of a pre-trained network.</li>
<li>Comparison of several architectures with a combination of different loss types.</li>
<li>80% of the cases ranked in top-3</li>
<li>Side benefit: clothing category classification</li>
</section>